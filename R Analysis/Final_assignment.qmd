---
title: "Final assignment"
format: pdf
editor: visual
---

# Final assignment BDSD

This is the Quarto file with the code for all the analysis done in the final assignment of Big Data, Small Data. The Github page "BDSD_final_assignment" contains all the files and information needed to follow this analysis. In the README.md file, which can be seen when you open the Github page, is all the information of where everything can be found and further information about the results of the project.

A link to the Github page: https://github.com/marleen101/BDSD_final_assignment/tree/main

In this file, the packages will firstly be installed and activated. Then the data set is imported and processed to work with during the analysis. The analysis will first be topic modelling. After the code for the visualizations for topic modelling, the code will be for collecting a small sample of the whole data set the further dive in to the data for the qualitative part of the study. There will be part to annotate the data and with this annotated data, a machine will be trained and used to annotate the whole data set, which will help us interpret information of the whole data set.

### **Loading packages**

```{r Loading packages, message=FALSE, warning=FALSE}
#install.packages(c("tidyverse", "curl", "stm", "reshape2","stringr", "caret", "stopwords", "tidytext", "textstem", stringi","remotes", "summarytools", "igraph", "ggraph","ggforce","ggwordcloud", "psych"))
library(remotes)
#remotes::install_github("ccs-amsterdam/annotinder-r")
library(tidyverse)
library(readr)
library(curl)
library(stm)
library(reshape2)
library(stringr)
library(caret)
library(stopwords)
library(tidytext)
library(textstem)
library(stringi)
library(annotinder)
library(summarytools)
library(igraph)
library(ggraph)
library(ggforce)
library(ggwordcloud)
library(psych)

```

### **Importing data from Github**

```{r from github, message=FALSE}

data_climatechange <- read_csv("https://raw.githubusercontent.com/marleen101/BDSD_final_assignment/refs/heads/main/Data/Data%20Climate%20Change/data_climatechange.csv")

```

This code will import data via the Github page made for this project. However, it is also possible to download the data from the Github page and import it manually by yourself. Look at the README.md file for further information on where the data set is stored on the page. The data from the individual subreddits can also be found in the same place.

### **Prepare the data set**

```{r preparing the dataset}
#Combining the title and the self text of each post in one variable
data_climatechange$text_all <- paste(data_climatechange$title,
                                     data_climatechange$selftext,
                                     sep = "\n")





#date variable, UTC time zone
data_climatechange <- data_climatechange %>%
  mutate(date = format(
    as.POSIXct(created_utc, origin = "1970-01-01", tz = "UTC"),
    "%Y-%m-%d %H:%M:%S"
  ))


#process for topic modelling
processed <- textProcessor(data_climatechange$text_all, metadata = data_climatechange) 
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)

```

For the pre-processing of the data set, the title and text of the post is combined in to one variable. Furthermore, is there a data variable made. Lastly, for topic modelling, the texts are processed (removing, for example, pronunciations, stop words, and numbers) and made in to a data frame which can be used for the analysis. This code showed that after processing five documents were removed from the analysis as there were no characters there anymore after stemming, removing stop words, punctuation, numbers.

### **Analysis**

#### Topic modelling

```{r amounts of topics for topic modelling}
set.seed(159)

# Criteria amount of topics with Coherence and Exclusivity

K_climate <- seq(10,60,by = 10) # for calculating the exclusivity and coherence with 10 till 60 topics, with the increment of the sequence of 10.


#code underneath is for creating different models with different amount of topics. It is possible to download the R Data file via the github page to save some time. The file is placed under the map Data and Topic model (file "fit_climate.rds").

####fit_climate <- searchK(processed$documents, processed$vocab, K= K_climate)
fit_climate <- readRDS("fit_climate.rds")

# Making the scores of Coherence and Exclusivity for each amount of topic
plot_climate <- data.frame("K" = K_climate, 
                   "Coherence" = unlist(fit_climate$results$semcoh),
                   "Exclusivity" = unlist(fit_climate$results$exclus))

plot_climate <- melt(plot_climate, id=c("K"))
plot_climate
climate_wider <- pivot_wider(plot_climate, names_from = variable, values_from = value)

#Plot results of the Coherence and Exclusivity
# Axis ranges
ylim_prim <- range(climate_wider$Coherence)
ylim_sec  <- range(climate_wider$Exclusivity)

# Scaling parameters
b <- diff(ylim_prim) / diff(ylim_sec)
a <- ylim_prim[1] - b * ylim_sec[1]

ggplot(climate_wider, aes(x = K)) +
  geom_line(aes(y = Coherence, color = "Coherence"), linewidth = 1) +
  geom_point(aes(y = Coherence, color = "Coherence"), size = 2) +
  geom_line(aes(y = Exclusivity * b + a, color = "Exclusivity"), linewidth = 1) +
  geom_point(aes(y = Exclusivity * b + a, color = "Exclusivity"), size = 2) +
  scale_y_continuous(
    name = "Coherence",
    sec.axis = sec_axis(~ (. - a)/b, name = "Exclusivity")
  ) +
  scale_color_manual(values = c("Coherence" = "coral2", "Exclusivity" = "seagreen3")) +
  labs(
    title = "Topic Model Diagnostics",
    x = "Number of Topics (K)",
    color = ""
  ) +
  theme(legend.position = "bottom")


```

A model was made to look at the exclusivity and coherence of different model. The different models where models where there are 10, 20, 30, 40, 50, or 60 topics. Looking at the visualization of the exclusivity and coherence of these models, it is decided to choose a model with 35 topics. The visualizations show that between 30 en 40 the exclusivity still increases, but coherence decreases. After 40 the exclusivity is stagnating, which shows that a max of 40 topics is good to have with this model. However, to limit the decrease of coherence, we chose to pick 35 topics. This model ensure that exclusivity is high and that it is not at the expense of the coherence of the model.

```{r topic modelling}
set.seed(159)

##to save time, it is also possible to download the rds file of topic_model on the github page and import it with the code underneath the topic modelling code. 
#topic_model <- stm(documents = out$documents,
#         vocab = out$vocab, 
#         K = 35,
#        verbose = TRUE)
topic_model <- readRDS("topic_model.rds")


theta <- make.dt(topic_model)
data_climatechange$Topic <- NA 


#there will be an error at the end for this code. No worries, this is caused, because 5 documents were not in the topic modelling as they didn't contain any characters anymore.
for (i in 1:nrow(data_climatechange)){
  column <- theta[i,-1]
  maintopic <- colnames(column)[which(column==max(column))]
  data_climatechange$Topic[i] <- maintopic
}

freq(data_climatechange$Topic)

#mean, standard deviation and median of the amount of words per posts per topic
data_climatechange %>%
  group_by(Topic)%>%
  summarise(mean = round(mean(str_count(text_all ,"\\W+")),2), 
            sd = round(sd(str_count(text_all ,"\\W+")),2),
            median = round(median(str_count(text_all, "\\W+")),2))



#the 15 top words of the topics
labels <- labelTopics(topic_model, n=15)
topwords <- data.frame("features"= t(labels$frex))
colnames(topwords)<- paste("Topic", c(1:35))

#see which documents were deleted from the process.
out[["docs.removed"]]
data_climatechange$text_all[c(1288,7407,7725,8252,8891)]




```

After examining the 20 most prominent posts for each topic and the corresponding top words, each topic was assigned a descriptive label. The labels and top words can be seen in Table 1.

| Topic | Content | Top words |
|------------------:|----------------------|-------------------------------|
| 1 | Places | Citi, town, Washington, san, london, York, local, rural, nyc |
| 2 | Vehicles | Car, bike, child, petrol, idl, drive, parent, walk, truck, great, road |
| 3 | Extinction (animals) | Nanoparticle, smuggle, ozon, ozone-deplet, livestock, feed, cattl, beef, pig, moor |
| 4 | Hopeless / doom perspectives | Thing, feel, dont, don’t, think, anyth, doom, els, realli, bad |
| 5 | Harm of certain kinds of electricity | Mongabay, bio-energi, palm, smil, Vaclav, euro, wri, miner, lithium, iea |
| 6 | Projects and studies for moderating climate change | Contruct, build, concret, paint, visibl, nich, network, homeown, recurs |
| 7 | Rising sea levels (melting ice/glaciers) | Glacier, ice, melt, sea, permafrost, sheer, antarctica, meter, arctic, antarct |
| 8 | Business investing in sustainability | Busi, money, company, fight, non-profit, chariti, sustain, credit, volunt, organ |
| 9 | Warming of 1.5 / 2 degrees Celsius | Ipcc, tip, report, warm, global, celsius, decad, degree, point, trajectori |
| 10 | Aviation (celebrities) | Cruis, elon, travel, plane, flight, fli, aviat, train, musk, richest |
| 11 | Coronavirus | Que, cambio, covid--, mundo, pandem, virus, covid, coronavirus, esto, breath |
| 12 | American politics | Elect, court, senat, voter, vote, trump, republican, presidenti, biden, administr |
| 13 | Oceans | Coral, invas, reef, speci, habitat, extinct, ecosystem, whale, ending, fish |
| 14 | Moral and ethical reflection | Society, moral, solv, cultur, politician, existenti, acknowledge, modern, greed |
| 15 | Critique of fossil fuels | Cop, fossil, fuel, confer, militari, oil, summit, leader, minist, host |
| 16 | Respondent recruitment | Survey, app, quastionnair, particip, interview, user, email, share, server, minut |
| 17 | Change in weather | Amok, atlant, stream, northern, gulf, rainfall, hemisphere, southern, circul, merdion |
| 18 | Alternative energy | Nuclear, reactor, hydrogen, power, uranium, solar, energi, kwh, renew, panel |
| 19 | Wanting to learn more | Chang, climat, combat, effect, affect, impact, posit, mitig, discuss, issu |
| 20 | Data | Model, data, graph, accur, rcp, observ, confid, predict, map, correl |
| 21 | Careers and degrees | Career, podcast, book, recommend, advic, college, fiction, episode, skill, master |
| 22 | Carbon | Dac, carbon, captur, offset, footprint, gwp, neutral, methan, ghg, dioxid |
| 23 | Natural disasters | Hurricane, wilfir, fire, flood, strom, drought, tornado, helen, disast, valley |
| 24 | Innovations for managing climate change | Strategi, challang, innov, ensur, secur, develop, sector, integr, crucial, econom |
| 25 | Trees | Tree, Ecosia, amazon, rainforest, forest, soil, deforest, harvest, fertile, plant |
| 26 | Cooling devices | Hot, heat, wave, hotter, humid, outisd, summer, pump, cold, cooler |
| 27 | Temperature records | Mayhem, warmest, abrupt, record, februari, niño, video, hottest |
| 28 | Country-level climate information | Country, capita, india, china, price, per, trillion, tonn, total, billion |
| 29 | Climate scepticism discussion | Argument, denier, claim, debat, convinc, denial, deni, debunk, skeptic, alarmist |
| 30 | Seasonal change patterns | Snow, ago, week, last spring, rememb, year, lake, normal, coupl |
| 31 | Sustainable alternative products | Reusable, groceri, bag, package, landfill, plastic, trash, wast, reus, item |
| 32 | Future outlooks | Will, future, happen, worst, realist, term, soon, becom, eventu, live |
| 33 | Recommendations to learn more | Anyon, guy, look, question, read, wonder, find, thought, topic, ask |
| 34 | Atmospheric composition | Radiat, cloud, geoengin, aerosol, ppm, concentr, vapor, erupt, volcano |
| 35 | Solutions for climate change | World, crisi, save, face, moment, bring, need, biggest, cricl, globe |

: Table 1: Thematic content of the topics

#### **Visualizations topic modelling**

```{r visualizations}
#Plot topics
plot(topic_model)

#Bar plot
ggplot(data_climatechange, aes(x=as.factor(Topic), fill = as.factor(subreddit)))+
  geom_bar()+
  theme(axis.text.x = element_text(angle = 35, hjust = 1))+
  labs(title= "Barplot of the distribution of Reddit posts between the topics and subreddits",
       x= "Topics", 
       y= "Frequency", 
       fill =  "Subreddit")


#Correlation plot
cor <- topicCorr(topic_model)
#simple network
plot(cor)

#Network analysis with clusters
network_pos <- cor$cor
network_pos[network_pos < 0] <- 0

for_network_plot <- graph_from_adjacency_matrix(
  network_pos,
  mode = "undirected",
  weighted = TRUE,
  diag = FALSE)

cluster_manual <- c(
  "1" = "Society and governance",
  "2" = "Technological and mitigation innovations",
  "3" = "Ecosystems",
  "4" = "Emotions",
  "5" = "Technological and mitigation innovations",
  "6" = "Technological and mitigation innovations",
  "7" = "Changing weather and atmospheric processes",
  "8" = "Society and governance",
  "9" = "Changing weather and atmospheric processes",
  "10"= "Technological and mitigation innovations",
  "11"= "Society and governance",
  "12"= "Society and governance",
  "13"= "Ecosystems",
  "14"= "Emotions",
  "15"= "Technological and mitigation innovations",
  "16"= "Information seeking and professional engagement",
  "17"= "Changing weather and atmospheric processes",
  "18"= "Technological and mitigation innovations",
  "19"= "Information seeking and professional engagement",
  "20"= "Information seeking and professional engagement",
  "21"= "Information seeking and professional engagement",
  "22"= "Technological and mitigation innovations",
  "23"= "Changing weather and atmospheric processes",
  "24"= "Technological and mitigation innovations",
  "25"= "Ecosystems",
  "26"= "Changing weather and atmospheric processes",
  "27"= "Changing weather and atmospheric processes",
  "28"= "Society and governance",
  "29"= "Information seeking and professional engagement",
  "30"= "Changing weather and atmospheric processes",
  "31"= "Technological and mitigation innovations",
  "32"= "Emotions",
  "33"= "Information seeking and professional engagement",
  "34"= "Changing weather and atmospheric processes",
  "35"= "Emotions")

V(for_network_plot)$name <- as.character(1:vcount(for_network_plot))
V(for_network_plot)$Cluster <- cluster_manual[V(for_network_plot)$name]
V(for_network_plot)$name <- paste0("Topic ", V(for_network_plot)$name)

cluster_colors <- c(
  "Emotions" = "darkorange",
  "Society and governance" = "steelblue1",
  "Information seeking and professional engagement" = "khaki",
  "Changing weather and atmospheric processes" = "firebrick",
  "Ecosystems" = "chartreuse2",
  "Technological and mitigation innovations" = "dodgerblue4")


ggraph(for_network_plot, layout = "fr") +
  geom_edge_link(aes(width = weight), 
                 alpha = 0.3, 
                 colour = "grey30") +
  geom_node_point(aes(color = Cluster),
                  size = 5) +
  geom_node_text(aes(label = name), 
                 repel = TRUE, 
                 size = 3) +
  geom_mark_hull(aes(x = x, y = y, group = Cluster, fill = Cluster), 
                 alpha = 0.3, 
                 concavity = 1, 
                 expand =0.03,
                 color = NA) +
  scale_color_manual(values = cluster_colors) +
  scale_fill_manual(values = cluster_colors) +
  labs(title = "Network of the relationship between the topics shown in six clusters")


#Wordclouds

labels_wordcloud <- labelTopics(topic_model, n=15)$frex
topword_wordcloud <- data.frame(labels_wordcloud)
colnames(topword_wordcloud) <- paste0("Topic_", 1:ncol(topword_wordcloud))

topwords_long <- topwords %>%
  pivot_longer(
    cols = everything(), 
    names_to = "Topic",
    values_to = "term") %>%
  group_by(Topic) %>%
  mutate(word_id = row_number(),      
         size = 16 - word_id,
         topic_num = as.numeric(gsub("Topic ", "", Topic)),
         group = ceiling(topic_num / 9)) %>% 
  ungroup()


# Group 1: Topics 1-9
topwords_long %>%subset(group == 1)%>%
  ggplot(aes(label = term, size = size)) +
  geom_text_wordcloud(area_corr = TRUE) +
  facet_wrap(~Topic, scales = "free") +
  scale_size_area(max_size = 12) +
  labs(title = "Word Clouds for Topics 1-9")

# Group 2: Topics 10-18
topwords_long %>% subset(group == 2)%>%
  ggplot(aes(label = term, size = size)) +
  geom_text_wordcloud(area_corr = TRUE) +
  facet_wrap(~Topic, scales = "free") +
  scale_size_area(max_size = 12) +
  labs(title = "Word Clouds for Topics 10-18")

# Group 3: Topics 19-27
topwords_long %>% subset(group == 3)%>%
  ggplot(aes(label = term, size = size)) +
  geom_text_wordcloud(area_corr = TRUE) +
  facet_wrap(~Topic, scales = "free") +
  scale_size_area(max_size = 12) +
  labs(title = "Word Clouds for Topics 19-27")

# Group 4: Topics 28-35
topwords_long %>% subset(group == 4)%>%
  ggplot(aes(label = term, size = size)) +
  geom_text_wordcloud(area_corr = TRUE) +
  facet_wrap(~Topic, scales = "free") +
  scale_size_area(max_size = 12) +
  labs(title = "Word Clouds for Topics 28-35")



```

#### **Content analysis**

```{r selection for qualitative analysis}
set.seed(159)
#sample of 342 posts, the file of the sample can be downloaded from github
#sample_annotate <- data_climatechange[sample(nrow(data_climatechange), size =342),]
sample_annotate <- readRDS("sample_annotate.rds")


#for doing a coding job
units <- create_units(sample_annotate,
                      id = "id",
                      set_text("text", text_all))


technique <- question("Neutralization technique", 
                      "Which neutralization technique is present in the post?",
                      codes = c(crimson = "None",
                                lightgreen = "Denial resp.",
                                dodgerblue = "Denial injury",
                                salmon = "Denial victim",
                                plum = "Condemnation", 
                                darkorange = "Higher loyalties",
                                grey = "Other"
                                ))

codebook <- create_codebook(technique)

job <- create_job("codejob_technique", units, codebook)
job_db <- create_job_db(job)

start_annotator(job_db)

```

```{r compare annotations}
#Gather the annotations 
#from Github
Annotator_1 <- readRDS("Annotator_1.rds")
Annotator_1<- Annotator_1[,-c(2,3)]

Annotator_2 <- readRDS("Annotator_2")
Annotator_2 <- Annotator_2[,-c(2,3)]

#When done with annotinder package
#Annotator_1 <- gimme_annotations(job_db)

confusionMatrix(as.factor(Annotator_1$value), as.factor(Annotator_2$value))

Annotated_combined <- Annotator_1 %>%
  left_join(Annotator_2, by = "id") 

Not_overlapping <- Annotated_combined[which(Annotated_combined$value.x != Annotated_combined$value.y),]


Id_error_analysis <- c("l6e673", "1ihsr2h", "1avueog", "volodh", "n36t2i", "myfqge", "u9odal", "1jnd905", "y9hrsi", "q2uk3i", "kvcmek", "1je1dck", "1g0mr94", "u0o4mt", "izj39e", "1cq8ph5")

#Posts for error analysis
data_climatechange$text_all[data_climatechange$id %in% Id_error_analysis]

Overlapping <- Annotated_combined[which(Annotated_combined$value.x == Annotated_combined$value.y),]

Id<- c("mlgn0d","o80ltk","fg76pe","1ggtxr6","1etur0g")


#The posts with the same annotated technique
data_climatechange$text_all[data_climatechange$id %in% Id]

#Adding the results in the data set
coding <- data.frame(
  id = sapply(units, `[[`, "id"),
  text = sapply(units, function(x) x$unit$text_fields[[1]]$value),
  stringsAsFactors = FALSE
)


Annotated_data_with_text <-  Annotated_combined%>%
  left_join(data_climatechange, by = "id")



Annotated_data_with_text$text_all[Annotated_data_with_text$value.y =="Condemnation"]




#Visualizations of annotations

ggplot(Annotated_data_with_text)+
  geom_bar(aes(x=value.y, fill = "Annotator 2"), alpha=.6)+
  geom_bar(aes(x=value.x, fill = "Annotator 1"), alpha=.6)+
  scale_fill_manual(values = c("Annotator 1" = "coral1",
                               "Annotator 2" = "seagreen"))+
  labs(title = "Annotated labels by the two annotators",
       fill =  "Annotator",
       x= "Label",
       y="Frequency")




```

#### Code for classification

Unfortunately due to time limitations this part of code was not added to the final study. The code here underneath is for classification of neutralization techniques used within posts. After annotating, the data can be used within a model which will classify the rest of the posts if it contains some sort of neutralization technique or not.

> Note!
>
> Your annotated data needs to be big, or contain enough data on which the model can predict. If the distribution between containing a technique and not is out of balance, the model will look at the data and see that classifying posts as not containing a technique has a higher probability. This results in the model not predicting any posts containing a technique.

```{r training for classification}
set.seed(159)

#Changing variable to a binary one. So it will be a variable stating if is does contain 
Annotation_binary  <- annotated_sample
Annotation_binary <- Annotation_binary %>%
  mutate(binary = case_when(value %in% c(
                            "Denial resp.",
                            "Denial injury",
                            "Denial victim",
                            "Condemnation",
                            "Higher loyalties",
                            "Other"
                          ) ~ "Yes",
                          value == "None" ~ "No"))

#Deviding the data in to testing (30%) and training (70%)
divide_test_train <- createDataPartition(Annotation_binary$binary, p = 0.70, list = FALSE)
train <- Annotation_binary[divide_test_train,]
test <- Annotation_binary[-divide_test_train,]


#The distribution between the two sets
ggplot() + 
  geom_bar(data = train, aes(x = binary), fill = "blue", alpha = .5) + 
  geom_bar(data = test, aes(x = binary),fill = "red", alpha = .5) +
  labs(color = "Density", title = "Random Sampling Distribution")


#Prepping for training and testing
#cleaning
tokens_train <- train %>%
  mutate(text = str_remove_all(text_all.y, "https?://\\S+")) %>%
  unnest_tokens(word, text) %>%
  mutate(
    word = str_remove_all(word, "@\\S+"),
    word = str_remove_all(word, "[[:punct:]]"),
    word = str_remove_all(word, "[[:digit:]]"),
    word = str_to_lower(word),
    word = stri_trans_general(word, "Latin-ASCII"),
    word = str_replace_all(word, "[^a-zA-Z0-9]", "")
  ) %>%
  filter(str_detect(word, "\\S")) %>%
  filter(!word %in% stopwords("en")) %>%
  mutate(word = lemmatize_words(word))


tokens_test <- test %>%
  mutate(text = str_remove_all(text_all.y, "https?://\\S+")) %>%
  unnest_tokens(word, text) %>%
  mutate(
    word = str_remove_all(word, "@\\S+"),
    word = str_remove_all(word, "[[:punct:]]"),
    word = str_remove_all(word, "[[:digit:]]"),
    word = str_to_lower(word),
    word = stri_trans_general(word, "Latin-ASCII"),
    word = str_replace_all(word, "[^a-zA-Z0-9]", "")
  ) %>%
  filter(str_detect(word, "\\S")) %>%
  filter(!word %in% stopwords("en")) %>%
  mutate(word = lemmatize_words(word))

#tokens to dtm
dtm_train <- tokens_train %>%
  rename(doc_id = id) %>%
  count(doc_id, word) %>%
  bind_tf_idf(word, doc_id, n) %>%
  select(doc_id, word, tf_idf) %>%
  pivot_wider(
    names_from = word,
    values_from = tf_idf,
    values_fill = 0
  )


dtm_test <- tokens_test %>%
  rename(doc_id = id) %>%
  count(doc_id, word) %>%
  bind_tf_idf(word, doc_id, n) %>%
  select(doc_id, word, tf_idf) %>%
  pivot_wider(
    names_from = word,
    values_from = tf_idf,
    values_fill = 0
  )


missing_cols <- setdiff(colnames(dtm_train), colnames(dtm_test))

for (col in missing_cols) {
  dtm_test[[col]] <- 0
}


#adding the labels
train <- rename(train, doc_id = id)
train_ml <- dtm_train %>%
  left_join(train %>% select(doc_id, binary), by = "doc_id")

test <- rename(test, doc_id = id)
test_ml <- dtm_test %>%
  left_join(test %>% select(doc_id, binary), by = "doc_id")

train_ml$binary <- as.factor(train_ml$binary)
test_ml$binary  <- as.factor(test_ml$binary)



control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary, 
  sampling = "smote"
)


#Training
train_model <- train(
  binary ~ .,
  data = train_ml %>% select(-doc_id),
  method = "glmnet",  
  trControl = control,
  metric = "ROC"
)

#Predict and evaluate 
prediction_model <- predict(train_model, test_ml)
confusionMatrix(prediction_model, test_ml$binary)
freq(test$binary)#this shows how the distribution of the techniques of golden standard (binary)

```
