---
title: "Final assignment"
format: pdf
editor: visual
---

### **Loading packages**

```{r Loading packages, message=FALSE, warning=FALSE}
#install.packages(c("tidyverse", "curl", "stm", "reshape2", "caret", "remotes", "stopwords", "tidytext", "textstem", "stringr", stringi", "xgboost"))
#remotes::install_github("ccs-amsterdam/annotinder-r")
library(tidyverse)
library(readr)
library(curl)
library(stm)
library(reshape2)
library(stringr)
library(annotinder)
library(caret)
library(stopwords)
library(tidytext)
library(textstem)
library(stringi)
library(xgboost)


here??????????
```

### **Importing data**

#### **From Github**

```{r from github}

data_climatechange <- read_csv("https://raw.githubusercontent.com/marleen101/BDSD_final_assignment/refs/heads/main/Data/Data%20Climate%20Change/data_climatechange.csv")

```

### **Prepare the data set**

```{r preparing the dataset}
#combining the title and the self text of each post in one variable
data_climatechange$text_all <- paste(data_climatechange$title,
                                     data_climatechange$selftext,
                                     sep = "\n")

#date variable, UTC time zone
data_climatechange <- data_climatechange %>%
  mutate(date = format(
    as.POSIXct(created_utc, origin = "1970-01-01", tz = "UTC"),
    "%Y-%m-%d %H:%M:%S"
  ))


#process for topic modelling
processed <- textProcessor(data_climatechange$text_all, metadata = data_climatechange) 
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)

```

5 documents are removed, as there were no characters there anymore after stemming, removing stop words, punctuation, numbers, lowercase etc.

### **analysis**

```{r amounts of topics for topic modelling}
set.seed(159)

# Criteria amount of topics with Coherence and Exclusivity

K_climate <- seq(10,60,by = 10) # for calculating the exclusivity and coherence with 10 till 60 topics, with the increment of the sequence of 10.


#code underneath is for creating different models with different amount of topics. It is possible to download the R Data file via the github page to save some time. The file is placed under the map Data and Topic model (file "fit_climate.rds").

####fit_climate <- searchK(processed$documents, processed$vocab, K= K_climate)
#fit_climate <- readRDS("fit_climate.rds")

# Making the scores of Coherence and Exclusivity for each amount of topic
plot_climate <- data.frame("K" = K_climate, 
                   "Coherence" = unlist(fit_climate$results$semcoh),
                   "Exclusivity" = unlist(fit_climate$results$exclus))

plot_climate <- melt(plot_climate, id=c("K"))
plot_climate
climate_wider <- pivot_wider(plot_climate, names_from = variable, values_from = value)

#Plot results of the Coherence and Exclusivity
# Axis ranges
ylim_prim <- range(climate_wider$Coherence)
ylim_sec  <- range(climate_wider$Exclusivity)

# Scaling parameters
b <- diff(ylim_prim) / diff(ylim_sec)
a <- ylim_prim[1] - b * ylim_sec[1]

ggplot(climate_wider, aes(x = K)) +
  geom_line(aes(y = Coherence, color = "Coherence"), linewidth = 1) +
  geom_point(aes(y = Coherence, color = "Coherence"), size = 2) +
  geom_line(aes(y = Exclusivity * b + a, color = "Exclusivity"), linewidth = 1) +
  geom_point(aes(y = Exclusivity * b + a, color = "Exclusivity"), size = 2) +
  scale_y_continuous(
    name = "Coherence",
    sec.axis = sec_axis(~ (. - a)/b, name = "Exclusivity")
  ) +
  scale_color_manual(values = c("Coherence" = "coral2", "Exclusivity" = "seagreen3")) +
  labs(
    title = "Topic Model Diagnostics",
    x = "Number of Topics (K)",
    color = ""
  ) +
  theme(legend.position = "bottom")


```

amount of topics 35, because this way we minimize the reducement of coherence, but still have the highest exclusivity rate.

```{r topic modelling}
set.seed(159)

##to save time, it is also possible to download the rds file of topic_model on the github page and import it with the code underneath the topic modelling code. 
#topic_model <- stm(documents = out$documents,
#         vocab = out$vocab, 
#         K = 35,
#        verbose = TRUE)

topic_model <- readRDS("topic_model.rds")


theta <- make.dt(topic_model)
data_climatechange$Topic <- NA 

for (i in 1:nrow(data_climatechange)){
  column <- theta[i,-1]
  maintopic <- colnames(column)[which(column==max(column))]
  data_climatechange$Topic[i] <- maintopic
}

freq(data_climatechange$Topic)

#mean, standard deviation and median of the amount of words per posts per topic
data_climatechange %>%
  group_by(Topic)%>%
  summarise(mean = round(mean(str_count(text_all ,"\\W+")),2), 
            sd = round(sd(str_count(text_all ,"\\W+")),2),
            median = round(median(str_count(text_all, "\\W+")),2))



#the 15 top words of the topics
labels <- labelTopics(topic_model, n=15)
topwords <- data.frame("features"= t(labels$frex))
colnames(topwords)<- paste("Topic", c(1:35))

#plot topics
plot(topic_model)

#cor plot
cor <- topicCorr(topic_model)
plot(cor)

#see which documents were deleted from the process.
out[["docs.removed"]]
data_climatechange$text_all[c(1288,7407,7725,8252,8891)]



```



```{r selection for qualitative analysis}
set.seed(159)
#sample of 275 posts, the file of the sample can be downloaded from github
#sample_annotate <- data_climatechange[sample(nrow(data_climatechange), size =275),]
sample_annotate <- saveRDS(sample_annotate, "Data/sample_annotate.rds")


#for doing a coding job
units <- create_units(sample_annotate,
                      id = "id",
                      set_text("text", text_all))

technique <- question("Neutralization technique", 
                      "Does this post consist of a neuralization technique?",
                      codes = c(crimson = "No",
                                lightgreen = "Yes"))

codebook <- create_codebook(technique)

job <- create_job("codejob_technique", units, codebook)
job_db <- create_job_db(job, overwrite = T)

start_annotator(job_db)

gimme_annotations(job_db)


sample_codejob <- gimme_annotations(job_db)
sample_codejob <- sample_codejob[,-c(2,3)]

coding <- data.frame(
  id = sapply(units, `[[`, "id"),
  text = sapply(units, function(x) x$unit$text_fields[[1]]$value),
  stringsAsFactors = FALSE
)

sample <- left_join(coding, sample_codejob, by= "id")
sample <- sample[,-c(3,4)]
colnames(sample)<- c("id", "text_all", "value")

annotated_sample <- sample_annotate %>%
  left_join(sample, by = "id")


```



```{r training for classification}
#train model for classifications, the test and train data can be found on github
#divide_test_train <- createDataPartition(annotated_sample$value, p = 0.75, list = FALSE)
#train <- annotated_sample[divide_test_train,]
train <- readRDS("train.rds")

#test <- annotated_sample[-divide_test_train,]

test <- readRDS("test.rds")

#the distribution between the two sets
ggplot() + geom_bar(data = train, aes(x = value), fill = "blue", alpha = .5) + geom_bar(data = test, aes(x = value),fill = "red", alpha = .5) + theme_bw() + labs(color = "Density", title = "Random Sampling (Caret package)",
    x = "yes/no")


#prepping for training and testing
#cleaning
tokens_train <- train %>%
  mutate(text = str_remove_all(text_all, "https?://\\S+")) %>%
  unnest_tokens(word, text) %>%
  mutate(
    word = str_remove_all(word, "@\\S+"),
    word = str_remove_all(word, "[[:punct:]]"),
    word = str_remove_all(word, "[[:digit:]]"),
    word = str_to_lower(word),
    word = stri_trans_general(word, "Latin-ASCII"),
    word = str_replace_all(word, "[^a-zA-Z0-9]", "")
  ) %>%
  filter(str_detect(word, "\\S")) %>%
  filter(!word %in% stopwords("en")) %>%
  mutate(word = lemmatize_words(word))


tokens_test <- test %>%
  mutate(text = str_remove_all(text_all, "https?://\\S+")) %>%
  unnest_tokens(word, text) %>%
  mutate(
    word = str_remove_all(word, "@\\S+"),
    word = str_remove_all(word, "[[:punct:]]"),
    word = str_remove_all(word, "[[:digit:]]"),
    word = str_to_lower(word),
    word = stri_trans_general(word, "Latin-ASCII"),
    word = str_replace_all(word, "[^a-zA-Z0-9]", "")
  ) %>%
  filter(str_detect(word, "\\S")) %>%
  filter(!word %in% stopwords("en")) %>%
  mutate(word = lemmatize_words(word))

#tokens to dtm
dtm_train <- tokens_train %>%
  rename(doc_id = id) %>%
  count(doc_id, word) %>%
  bind_tf_idf(word, doc_id, n) %>%
  select(doc_id, word, tf_idf) %>%
  pivot_wider(
    names_from = word,
    values_from = tf_idf,
    values_fill = 0
  )


dtm_test <- tokens_test %>%
  rename(doc_id = id) %>%
  count(doc_id, word) %>%
  bind_tf_idf(word, doc_id, n) %>%
  select(doc_id, word, tf_idf) %>%
  pivot_wider(
    names_from = word,
    values_from = tf_idf,
    values_fill = 0
  )


missing_cols <- setdiff(colnames(dtm_train), colnames(dtm_test))

for (col in missing_cols) {
  dtm_test[[col]] <- 0
}


#adding the labels
colnames(train)<- c("doc_id", "subreddit", "created_utc", "author", "title", "selftext","retrieved_on", "score", "url", "text_all", "Topic", "text", "value") 

train_ml <- dtm_train %>%
  left_join(train %>% select(doc_id, value), by = "doc_id")

colnames(test)<- c("doc_id", "subreddit", "created_utc", "author", "title", "selftext","retrieved_on", "score", "url", "text_all", "Topic", "text", "value") 

test_ml <- dtm_test %>%
  left_join(test %>% select(doc_id, value), by = "doc_id")

train_ml$value.y <- as.factor(train_ml$value.y)
test_ml$value.y  <- as.factor(test_ml$value.y)



control <- trainControl(
  method = "cv",
  number = 5,
  classProbs = TRUE,
  summaryFunction = twoClassSummary, 
  sampling = "smote"
)


#training
train_model <- train(
  value.y ~ .,
  data = train_ml %>% select(-doc_id),
  method = "xgboost",  
  trControl = control,
  metric = "ROC"
)


#predict and evaluate 
prediction_model <- predict(train_model, test_ml)
confusionMatrix(prediction_model, test_ml$value.y)

prob <- predict(train_model, test_ml, type = "prob")

```



